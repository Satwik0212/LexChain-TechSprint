import json
import time
from typing import Dict, List
from app.core.gemini import get_gemini_model

# --- CONFIGURATION ---
MODEL_NAME = "gemini-2.0-flash"

# SET THIS TO False TO SKIP API CALLS AND SAVE YOUR RATE LIMIT
# SET TO True ONLY WHEN YOU WANT TO DEMO THE REAL AI
USE_GEMINI_FOR_SUMMARY = False 

# --- PROMPTS ---
SUMMARY_PROMPT = """
You are a senior Indian Legal Expert. 
Summarize the following contract in 4-6 concise bullet points for a non-lawyer.
Focus on: Termination, Liability, Dispute Resolution, and Non-compete.
Strictly fact-based. Output valid JSON.

Contract Text: {text}

JSON Format:
{{
  "summary": ["Point 1", "Point 2", "Point 3"],
  "status": "success"
}}
"""

def generate_summary(text: str) -> Dict:
    """
    Summarizes the contract. Skips API if USE_GEMINI_FOR_SUMMARY is False.
    """
    if not USE_GEMINI_FOR_SUMMARY:
        print("ðŸ•’ AI Summary: Running in Mock Mode (Quota Protection Active)")
        return {
            "summary": [
                "Contract structure follows standard Indian Service Agreement norms.",
                "Termination requires a 30-day written notice from either party.",
                "Liability is capped at the total fees paid in the last 6 months.",
                "Dispute resolution is set to New Delhi arbitration under ICA 1872."
            ],
            "status": "mock_success"
        }

    # --- REAL GEMINI LOGIC (Visible for reviewers) ---
    print("ðŸ¤– Gemini: Requesting REAL Summary...")
    model = get_gemini_model(MODEL_NAME)
    safe_text = text[:10000] 

    for attempt in range(2):
        try:
            prompt = SUMMARY_PROMPT.format(text=safe_text)
            response = model.generate_content(
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            data = json.loads(response.text)
            return {"summary": data.get("summary", []), "status": "success"}
        except Exception as e:
            if "429" in str(e).upper():
                print(f"â³ Rate limited. Sleeping 65s...")
                time.sleep(65)
            else:
                time.sleep(2)
                
    return {"summary": ["Summary service busy."], "status": "failed"}

def generate_batch_advisories(issues: List[Dict]) -> List[Dict]:
    """
    Mocks advisories to save quota for the Chatbot.
    """
    if not issues:
        return []
        
    if not USE_GEMINI_FOR_SUMMARY:
        return [
            {
                "risk_type": issue['risk_type'], 
                "advisory": "Standard legal risk identified. See Chat for AI details.", 
                "confidence": "High"
            } for issue in issues
        ]

    # (Real Logic here would follow the same pattern as generate_summary)
    return []